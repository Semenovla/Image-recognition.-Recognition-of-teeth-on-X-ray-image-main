{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('runs/segment/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"C:/Users/leva/Desktop/inst_segm/P1/77.jpg\")\n",
    "\n",
    "results = model(img, imgsz=640, iou=0.8, conf=0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(results[0].masks.data[1].cpu().numpy(), 'gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming results[0].masks.data contains multiple masks\n",
    "num_masks = results[0].masks.data.shape[0]  # Get the number of masks\n",
    "cols = 3  # Number of columns for the subplot\n",
    "rows = (num_masks + cols - 1) // cols  # Calculate number of rows needed\n",
    "\n",
    "plt.figure(figsize=(15, 5 * rows))  # Adjust figure size based on number of rows\n",
    "\n",
    "for i in range(num_masks):\n",
    "    plt.subplot(rows, cols, i + 1)  # Create a subplot for each mask\n",
    "    plt.imshow(results[0].masks.data[i].cpu().numpy(), cmap='gray')  # Display the mask\n",
    "    plt.axis('off')  # Optionally turn off axis\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()  # Render all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Предположим, что у вас есть несколько масок в results[0].masks.data\n",
    "masks = results[0].masks.data.cpu().numpy()  # Получаем маски и переводим на CPU\n",
    "num_masks = masks.shape[0]  # Количество масок\n",
    "\n",
    "# Создаем пустое изображение для наложения масок\n",
    "combined_image = np.zeros((masks.shape[1], masks.shape[2], 3), dtype=np.uint8)  # RGB изображение\n",
    "\n",
    "# Определяем цвет для каждой маски (можно настроить по желанию)\n",
    "colors = plt.cm.jet(np.linspace(0, 1, num_masks))[:, :3]  # Получаем цвета из колор-карты\n",
    "\n",
    "# Накладываем каждую маску на комбинированное изображение\n",
    "for i in range(num_masks):\n",
    "    mask = masks[i]\n",
    "    color = (colors[i] * 255).astype(np.uint8)  # Преобразуем цвет в формат uint8\n",
    "    combined_image[mask > 0] = color  # Накладываем цвет на область маски\n",
    "\n",
    "# Отображаем итоговое изображение\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(combined_image)\n",
    "plt.axis('off')  # Отключаем оси\n",
    "plt.title('Combined Masks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'results' and 'img' are defined earlier in your code\n",
    "classes = results[0].boxes.cls.cpu().numpy()\n",
    "class_names = results[0].names\n",
    "\n",
    "masks = results[0].masks.data\n",
    "num_masks = masks.shape[0]\n",
    "\n",
    "# Generate random colors for each mask\n",
    "colors = [tuple(np.random.randint(0, 256, 3).tolist()) for _ in range(num_masks)]\n",
    "\n",
    "# Create an overlay for the masks and a labeled image copy\n",
    "mask_overlay = np.zeros_like(img)\n",
    "labeled_image = img.copy()\n",
    "\n",
    "for i in range(num_masks):\n",
    "    color = colors[i]\n",
    "    mask = masks[i].cpu()\n",
    "\n",
    "    # Resize the mask to match the original image size\n",
    "    mask_resized = cv2.resize(np.array(mask), (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    class_index = int(classes[i])\n",
    "    class_name = class_names[class_index]\n",
    "\n",
    "    # Find contours from the resized mask\n",
    "    mask_contours, _ = cv2.findContours(mask_resized.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw contours on the labeled image\n",
    "    cv2.drawContours(labeled_image, mask_contours, -1, color, 5)\n",
    "\n",
    "    # Put text on the labeled image at the mean position of the contour\n",
    "    if len(mask_contours) > 0:\n",
    "        text_position = (int(mask_contours[0][:, 0, 0].mean()), int(mask_contours[0][:, 0, 1].mean()))\n",
    "        cv2.putText(labeled_image, class_name, text_position, cv2.FONT_HERSHEY_COMPLEX, 1, color, 2)\n",
    "\n",
    "# Display the labeled image\n",
    "plt.figure(figsize=(8, 8), dpi=150)\n",
    "labeled_image = cv2.cvtColor(labeled_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(labeled_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "\n",
    "def process_video_with_tracking(model, input_video_path, show_video=True, save_video=False, output_video_path=\"output_video.mp4\"):\n",
    "    # Open the input video file\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Error: Could not open video file.\")\n",
    "\n",
    "    # Get input video frame rate and dimensions\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define the output video writer\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps/2, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        results = model.track(frame, iou=0.6, conf=0.75, persist=True, imgsz=640, verbose=False, tracker=\"botsort.yaml\")\n",
    "\n",
    "        if results[0].boxes.id != None: # this will ensure that id is not None -> exist tracks\n",
    "            boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "            ids = results[0].boxes.id.cpu().numpy().astype(int)\n",
    "\n",
    "            for box, id in zip(boxes, ids):\n",
    "                # Generate a random color for each object based on its ID\n",
    "                random.seed(int(id))\n",
    "                color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "                \n",
    "                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3],), color, 4)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    f\"Id {id}\",\n",
    "                    (box[0], box[1]),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.5,\n",
    "                    (0, 255, 255),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "        if save_video:\n",
    "            out.write(frame)\n",
    "\n",
    "        if show_video:\n",
    "            frame = cv2.resize(frame, (frame.shape[1]//2, frame.shape[0]//2))\n",
    "            cv2.imshow(\"frame\", frame)\n",
    "\n",
    "        if cv2.waitKey(int(1000/fps)) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Release the input video capture and output video writer\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "model = YOLO('runs/segment/train/weights/best.pt')\n",
    "process_video_with_tracking(model, input_video_path=\"video1_2.mp4\",\n",
    "                                          show_video=True, save_video=False,\n",
    "                                          output_video_path=\"result_videos/output_video.mp4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
